{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870213d-452e-4761-bf41-353d3e95c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd1339-aca4-4eef-839c-3f8c7dbb7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309ef23a-18bb-43f4-84dc-a920963d524b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 15:29:07.760183: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from PIL import Image, ImageFile\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import json\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import XLNetModel, XLNetTokenizerFast\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df42a46-aeb2-4992-847d-cea7b6c96f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "tokenizer = XLNetTokenizerFast.from_pretrained(\"xlnet-base-cased\")\n",
    "pre_trained_model = XLNetModel.from_pretrained(\"xlnet-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b78e08-8424-40fc-8338-de7618b480fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextQuType:\n",
    "    def __init__(self, tokenizer, length, ids, context, question):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.codeLength = length\n",
    "        self.ids = ids\n",
    "        self.context = context\n",
    "        self.question = question\n",
    "        self.after_encode = 0\n",
    "        \n",
    "    def convert(self):\n",
    "        if self.after_encode==0:\n",
    "            after_encode = tokenizer(self.question,self.context,max_length=self.codeLength,padding=\"max_length\")\n",
    "        return torch.stack([torch.tensor(after_encode['input_ids'][-512:]),torch.tensor(after_encode['token_type_ids'][-512:]),torch.tensor(after_encode['attention_mask'][-512:])])\n",
    "        \n",
    "class LabelType:\n",
    "    def __init__(self, tokenizer, length, CQu, has_ans, text, start):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.codeLength = length\n",
    "        self.has_ans = has_ans\n",
    "        self.text = text\n",
    "        self.start = start\n",
    "        self.CQu = CQu\n",
    "    \n",
    "    def convert(self):\n",
    "        # make groundtruth\n",
    "        S = [0.0] * self.codeLength\n",
    "        E = [0.0] * self.codeLength\n",
    "        background = tokenizer.encode(self.CQu.question,self.CQu.context,max_length=self.codeLength,padding=\"max_length\")\n",
    "        length_exceed = False\n",
    "        if len(background) > self.codeLength:\n",
    "            length_exceed = True\n",
    "        if self.has_ans:\n",
    "            after_encode = tokenizer.encode(self.text)[:-2]\n",
    "            ans_length = len(after_encode)\n",
    "            after_answer = tokenizer.encode(self.CQu.context[self.start:])\n",
    "            if length_exceed:\n",
    "                start_id = len(background) - len(after_answer)\n",
    "                end_id = start_id + ans_length -1\n",
    "                if tokenizer.decode(background[start_id:end_id+1])!=self.text:\n",
    "                    lower = max(start_id-3,0)\n",
    "                    upper = min(end_id+4,len(background))\n",
    "                    ans_found = False\n",
    "                    for i in range(lower,upper):\n",
    "                        for j in range(i+1,upper):\n",
    "                            if tokenizer.decode(background[i:j])==self.text:\n",
    "                                start_id = i\n",
    "                                end_id = j-1\n",
    "                                ans_found = True\n",
    "                                break\n",
    "                            if ans_found:\n",
    "                                break\n",
    "                if end_id >= self.codeLength:\n",
    "                    end_id = self.codeLength-1\n",
    "                if start_id >= self.codeLength:\n",
    "                    start_id = 0\n",
    "                    end_id = 0\n",
    "                S[start_id] = 1.0\n",
    "                E[end_id] = 1.0\n",
    "            else:\n",
    "                start_id = len(background) - len(after_answer)\n",
    "                end_id = start_id + ans_length -1\n",
    "                if tokenizer.decode(background[start_id:end_id+1])!=self.text:\n",
    "                    lower = max(start_id-3,0)\n",
    "                    upper = min(end_id+4,len(background))\n",
    "                    ans_found = False\n",
    "                    for i in range(lower,upper):\n",
    "                        for j in range(i+1,upper):\n",
    "                            candidate = tokenizer.decode(background[i:j])\n",
    "                            if len(candidate)>0:\n",
    "                                if candidate[0]=='$' and self.text[0]!='$':\n",
    "                                    candidate=candidate[1:]\n",
    "                                if candidate[0]!='$' and self.text[0]=='$':\n",
    "                                    candidate='$'+candidate\n",
    "                            if candidate==self.text:\n",
    "                                start_id = i\n",
    "                                end_id = j-1\n",
    "                                ans_found = True\n",
    "                                break\n",
    "                            if ans_found:\n",
    "                                break\n",
    "                S[start_id] = 1.0\n",
    "                E[end_id] = 1.0\n",
    "            #if tokenizer.decode(background[start_id:end_id+1])!=self.text:\n",
    "                #print(tokenizer.convert_ids_to_tokens(background))\n",
    "                #print(tokenizer.decode(after_answer[:ans_length])+'|||'+tokenizer.decode(background[start_id:end_id+1])+'|||'+self.text)\n",
    "                #print(len(background),len(after_answer),start_id,end_id)\n",
    "                #print(self.CQu.context[self.start:self.start+len(self.text)]+'|||'+tokenizer.decode(after_encode)+'|||',tokenizer.convert_ids_to_tokens(after_encode))\n",
    "        else:\n",
    "            S[-1] = 1.0\n",
    "            E[-1] = 1.0\n",
    "        return torch.stack([torch.tensor(S),torch.tensor(E)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b96639f-9c3d-4c7b-9b74-fde3927766f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(load_path,tokenizer,length):\n",
    "    with open(load_path) as json_data:\n",
    "        dev = json.load(json_data)['data']\n",
    "    CQu = []\n",
    "    Label = []\n",
    "    for data in dev:\n",
    "        for paragraphs in data['paragraphs']:\n",
    "            context = paragraphs['context']\n",
    "            for qas in paragraphs['qas']:\n",
    "                question = qas['question']\n",
    "                ids = qas['id']\n",
    "                ctx = ContextQuType(tokenizer,length,ids,context,question)\n",
    "                CQu.append(ctx)\n",
    "                if qas['is_impossible']:\n",
    "                    Label.append(LabelType(tokenizer,length,ctx,False,'',0))\n",
    "                else:\n",
    "                    answer = qas['answers'][0]\n",
    "                    Label.append(LabelType(tokenizer,length,ctx,True,answer['text'],answer['answer_start']))\n",
    "    return CQu,Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc85e75-9fa2-4082-bd42-fef5da59b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputPair:\n",
    "    def __init__(self,logits_start,logits_end):\n",
    "        self.logits_start = logits_start\n",
    "        self.logits_end = logits_end\n",
    "\n",
    "class CrossEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropy, self).__init__()\n",
    "    def forward(self,outputs,labels):\n",
    "        log_soft = F.log_softmax(outputs.logits_start,dim=1)\n",
    "        loss_start = F.cross_entropy(log_soft, labels[:,0])\n",
    "        loss_end   = F.cross_entropy(F.log_softmax(outputs.logits_end,dim=1), labels[:,1])\n",
    "        return loss_start + loss_end / 2.0\n",
    "\n",
    "class BERTQuA(nn.Module):\n",
    "    def __init__(self, bert, tokenizer,code_length,device,epsilon = 1.0):\n",
    "        super(BERTQuA, self).__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.encoder = bert.to(device)\n",
    "        self.code_length = code_length\n",
    "        self.output_start = nn.Linear(768,1).to(device)\n",
    "        self.output_end = nn.Linear(768,1).to(device)\n",
    "        self.epsilon = 1.0\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        tokens_X, segments_X, masks = inputs[:,0],inputs[:,1],inputs[:,2]\n",
    "        encoded_X = self.encoder(tokens_X, token_type_ids=segments_X, attention_mask=masks).last_hidden_state\n",
    "        return OutputPair(self.output_start(encoded_X),self.output_end(encoded_X))\n",
    "        \n",
    "    def prediction(self,question,answer_text):\n",
    "        ctx = ContextQuType(self.tokenizer,self.code_length,'',answer_text,question)\n",
    "        inputs = torch.stack([ctx.convert()]).to(device)\n",
    "        token_ids = tokenizer(question,answer_text,max_length=self.code_length,padding=\"max_length\")['input_ids']\n",
    "        outputs = self.forward(inputs)\n",
    "        start_scores = outputs.logits_start.reshape(-1)\n",
    "        end_scores = outputs.logits_end.reshape(-1)\n",
    "        no_ans_scores = start_scores[-1] + end_scores[-1]\n",
    "        answer = ''\n",
    "        tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "        #print(outputs.logits_start.reshape(-1))\n",
    "        #print(outputs.logits_end.reshape(-1))\n",
    "        if (torch.max(start_scores) + torch.max(end_scores) <= no_ans_scores +  self.epsilon):\n",
    "            answer = ''\n",
    "        else:\n",
    "            add_space = False\n",
    "            answer_start = torch.argmax(start_scores)\n",
    "            answer_end = torch.argmax(end_scores)\n",
    "            answer = self.tokenizer.decode(token_ids[answer_start:answer_end+1])\n",
    "        return answer\n",
    "    def predictionLabel(self,label):\n",
    "        #ctx = ContextQuType(self.tokenizer,self.code_length,'',answer_text,question)\n",
    "        #inputs = torch.stack([ctx.convert()]).to(device)\n",
    "        #token_ids = tokenizer(question,answer_text,max_length=self.code_length,padding=\"max_length\")['input_ids']\n",
    "        #outputs = self.forward(inputs)\n",
    "        outputs = label.convert()\n",
    "        #print(outputs)\n",
    "        token_ids = tokenizer(label.CQu.question,label.CQu.context,max_length=self.code_length,padding=\"max_length\")['input_ids']\n",
    "        start_scores = outputs[0,:]\n",
    "        end_scores = outputs[1,:]\n",
    "        #print(start_scores,end_scores)\n",
    "        no_ans_scores = start_scores[-1] + end_scores[-1]\n",
    "        answer = ''\n",
    "        tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "        #print(outputs.logits_start.reshape(-1))\n",
    "        #print(outputs.logits_end.reshape(-1))\n",
    "        if (torch.max(start_scores) + torch.max(end_scores) <= no_ans_scores +  self.epsilon):\n",
    "            answer = ''\n",
    "        else:\n",
    "            answer_start = torch.argmax(start_scores)\n",
    "            answer_end = torch.argmax(end_scores)\n",
    "            answer = self.tokenizer.decode(token_ids[answer_start:answer_end+1])\n",
    "        return answer\n",
    "    def load_data(self,file_path):\n",
    "        CQu, La = load_data(file_path,self.tokenizer,self.code_length)\n",
    "        self.inputs = torch.stack([ctx.convert() for ctx in CQu])\n",
    "        self.labels = torch.stack([ctx.convert() for ctx in La])\n",
    "    \n",
    "    def train(self, epochs=3, batch_size = 48, lr = 3e-5, T=10):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = CrossEntropy().to(device)\n",
    "        self.train_loader = DataLoader(TensorDataset(self.inputs,self.labels),batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "        epoch_loss = []\n",
    "        for epoch in range(epochs):      \n",
    "            running_loss = 0.0\n",
    "            epoch_running_loss = 0.0\n",
    "            batch_count = 0\n",
    "            for batchidx, (x, label) in enumerate(self.train_loader):\n",
    "                x, label = x.to(device), label.to(device)\n",
    "                output = self.forward(x)\n",
    "                output.logits_start=output.logits_start.resize(len(output.logits_start),self.code_length)\n",
    "                output.logits_end=output.logits_end.resize(len(output.logits_end),self.code_length)\n",
    "                loss = criterion(output, label)\n",
    "                # backprop\n",
    "                optimizer.zero_grad()  #梯度清0\n",
    "                loss.backward()   #梯度反传\n",
    "                optimizer.step()   #保留梯度\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                epoch_running_loss += loss.item()\n",
    "                batch_count += 1\n",
    "                if batchidx % T == T-1:\n",
    "                    print(epoch,' batchidx: ', batchidx, ' loss: ', running_loss/T)\n",
    "                    running_loss = 0.0\n",
    "            epoch_loss.append(epoch_running_loss/batch_count)\n",
    "            print(epoch, 'loss:', epoch_running_loss/batch_count)\n",
    "        return epoch_loss\n",
    "    def printLabel(self,file_path):\n",
    "        CQu, La = load_data(file_path,self.tokenizer,self.code_length)\n",
    "        count = 0\n",
    "        precise = 0\n",
    "        for label in La:\n",
    "            count += 1\n",
    "            predict = self.predictionLabel(label)\n",
    "            if predict==label.text:\n",
    "                precise += 1\n",
    "            #else:\n",
    "            #    print(predict,label.text,label.has_ans)\n",
    "        print(precise/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ec9d62-0604-4eed-83c3-8b6e1aeaa123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9840725746875092\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "net = BERTQuA(pre_trained_model,tokenizer,512,device)\n",
    "net.load_data('classifySimBertCluster2.json')\n",
    "net.printLabel('classifySimBertCluster2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba42be-008a-4086-a94b-9175f2f4c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss = net.train(batch_size=16,epochs=3)\n",
    "f = open(\"loss_cluster2.txt\", \"w\")\n",
    "f.write(str(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ec2a11-a4cc-4cba-89fd-70f22ebe0965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"Which journalist considered Spectre the worst James Bond movie in three decades?\"\"\"\n",
    "context = \"\"\"Critical appraisal of the film was mixed in the United States. In a lukewarm review for RogerEbert.com, Matt Zoller Seitz gave the film 2.5 stars out of 4, describing Spectre as inconsistent and unable to capitalise on its potential. Kenneth Turan, reviewing the film for Los Angeles Times, concluded that Spectre \\\"comes off as exhausted and uninspired\\\". Manohla Dargis of The New York Times panned the film as having \\\"nothing surprising\\\" and sacrificing its originality for the sake of box office returns. Forbes' Scott Mendelson also heavily criticised the film, denouncing Spectre as \\\"the worst 007 movie in 30 years\\\". Darren Franich of Entertainment Weekly viewed Spectre as \\\"an overreaction to our current blockbuster moment\\\", aspiring \\\"to be a serialized sequel\\\" and proving \\\"itself as a Saga\\\". While noting that \\\"[n]othing that happens in Spectre holds up to even minor logical scrutiny\\\", he had \\\"come not to bury Spectre, but to weirdly praise it. Because the final act of the movie is so strange, so willfully obtuse, that it deserves extra attention.\\\" In a positive review Rolling Stone, Peter Travers gave the film 3.5 stars out of 4, describing \\\"The 24th movie about the British MI6 agent with a license to kill is party time for Bond fans, a fierce, funny, gorgeously produced valentine to the longest-running franchise in movies\\\". Other positive reviews from Mick LaSalle from the San Francisco Chronicle, gave it a perfect 100 score, stating: \\u201cOne of the great satisfactions of Spectre is that, in addition to all the stirring action, and all the timely references to a secret organization out to steal everyone\\u2019s personal information, we get to believe in Bond as a person.\\u201d Stephen Whitty from the New York Daily News, gave it an 80 grade, saying: \\u201cCraig is cruelly efficient. Dave Bautista makes a good, Oddjob-like assassin. And while Lea Seydoux doesn\\u2019t leave a huge impression as this film\\u2019s \\u201cBond girl,\\u201d perhaps it\\u2019s because we\\u2019ve already met \\u2014 far too briefly \\u2014 the hypnotic Monica Bellucci, as the first real \\u201cBond woman\\u201d since Diana Rigg.\\u201d Richard Roeper from the Chicago Sun-Times, gave it a 75 grade. He stated: \\u201cThis is the 24th Bond film and it ranks solidly in the middle of the all-time rankings, which means it\\u2019s still a slick, beautifully photographed, action-packed, international thriller with a number of wonderfully, ludicrously entertaining set pieces, a sprinkling of dry wit, myriad gorgeous women and a classic psycho-villain who is clearly out of his mind but seems to like it that way.\\u201d Michael Phillips over at the Chicago Tribune, gave it a 75 grade. He stated: \\u201cFor all its workmanlike devotion to out-of-control helicopters, \\u201cSpectre\\u201d works best when everyone\\u2019s on the ground, doing his or her job, driving expensive fast cars heedlessly, detonating the occasional wisecrack, enjoying themselves and their beautiful clothes.\\u201d Guy Lodge from Variety, gave it a 70 score, stating: \\u201cWhat\\u2019s missing is the unexpected emotional urgency of \\u201cSkyfall,\\u201d as the film sustains its predecessor\\u2019s nostalgia kick with a less sentimental bent.\\u201d\"\"\"\n",
    "net.prediction(question,context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9b2391-b968-47b9-aaf8-341de851fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'state_dict': net.state_dict(), 'epoch':3},'xlnetCluster2'+str(3) + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
